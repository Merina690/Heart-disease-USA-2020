
# Heart disease analysis USING EDA

Heart disease dataset cleaning involves the process of identifying and correcting errors, inconsistencies, and inaccuracies in the dataset related to heart disease and their parameters. This process is crucial in ensuring that the data is accurate, reliable, and suitable for analysis. The steps involved in heart disease data cleaning may include:

Handling missing values: Identifying and handling missing data in the dataset by either removing records with missing data or imputing the missing values using appropriate techniques.

Handling outliers: Identifying and handling outliers in the dataset that may skew the analysis results.Visualizing them with boxplot

Standardizing data: Ensuring that the data is consistent in terms of measurement units, formats, and scales.

Data Visualization: visualizing the data to understand more about the data and get insight from them

Identifying errors: Identifying and correcting errors in the dataset such as data entry errors, typographical errors, and incorrect values.

## Lesson learnt
Exploratory Data Analysis (EDA) is a critical step in any data analysis project. Here are some key lessons that can be learned from EDA:

Data quality: EDA can reveal issues with data quality such as missing values, inconsistent data, or outliers. It's important to address these issues before proceeding with any analysis.

Data distribution: EDA helps in understanding the distribution of the data. It can help in identifying if the data is normally distributed or skewed, which can influence the choice of statistical tests.

Correlation: EDA can reveal correlations between variables. It's important to understand these correlations before proceeding with any analysis to avoid spurious relationships.

Data outliers: EDA helps in identifying outliers, which can have a significant impact on the analysis. It's important to understand the cause of these outliers and decide whether to exclude or include them in the analysis.

Overall, EDA is a crucial step in any data analysis project, and it's important to take the time to thoroughly explore and understand the data before proceeding with any analysis.




## ðŸš€ About Me

I'm a certified Data Scientist and a MBA graduate, worked on various projects in Machine Learning, Deep Learning, NLP, Tableau, PowerBI in creating the dashboards

## ðŸ›  Skills
Python, SQL, PowerBI, Tableau, machine learning, deep learning, NLP.


## ðŸ”— LINKS
[![portfolio](https://img.shields.io/badge/my_portfolio-000?style=for-the-badge&logo=ko-fi&logoColor=white)](https://merinaangel6905.wixsite.com/merina-angel/)
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/gaini-merina-angel-16052b214/)

## Related

Here are some related projects

[Penguin Data Cleaning](https://github.com/Merina690/penguin-size--EDA-PROCESS)

[Uber_data_analysis](https://github.com/Merina690/Uber_data_analysis)

## Support

EMAIL: merinaangel6905@gmail.com

